{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c4817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from\n",
    "# https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/11.multi-label-text-classification-with-bert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f61b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1479de76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rules_text</th>\n",
       "      <th>colors</th>\n",
       "      <th>color_identity</th>\n",
       "      <th>flavour_text</th>\n",
       "      <th>type_line</th>\n",
       "      <th>power</th>\n",
       "      <th>toughness</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Static Orb</td>\n",
       "      <td>As long as CARDNAME is untapped, players can't...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artifact</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sensory Deprivation</td>\n",
       "      <td>Enchant creature\\nEnchanted creature gets -3/-0.</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enchantment — Aura</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>m14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road of Return</td>\n",
       "      <td>Choose one —\\n• Return target permanent card f...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>c19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Storm Crow</td>\n",
       "      <td>Flying (This creature can't be blocked except ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creature — Bird</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Walking Sponge</td>\n",
       "      <td>tap: Target creature loses your choice of fly...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creature — Sponge</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ulg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24444</th>\n",
       "      <td>Quarry Beetle</td>\n",
       "      <td>When CARDNAME enters the battlefield, you may ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creature — Insect</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>hou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24445</th>\n",
       "      <td>Devoted Hero</td>\n",
       "      <td></td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creature — Elf Soldier</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>s99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24446</th>\n",
       "      <td>Without Weakness</td>\n",
       "      <td>Target creature you control gains indestructib...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instant</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>hou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24447</th>\n",
       "      <td>Firesong and Sunspeaker</td>\n",
       "      <td>Red instant and sorcery spells you control hav...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Legendary Creature — Minotaur Cleric</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2x2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24448</th>\n",
       "      <td>Sinew Sliver</td>\n",
       "      <td>All Sliver creatures get +1/+1.</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creature — Sliver</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tsr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24449 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name   \n",
       "0                   Static Orb  \\\n",
       "1          Sensory Deprivation   \n",
       "2               Road of Return   \n",
       "3                   Storm Crow   \n",
       "4               Walking Sponge   \n",
       "...                        ...   \n",
       "24444            Quarry Beetle   \n",
       "24445             Devoted Hero   \n",
       "24446         Without Weakness   \n",
       "24447  Firesong and Sunspeaker   \n",
       "24448             Sinew Sliver   \n",
       "\n",
       "                                              rules_text              colors   \n",
       "0      As long as CARDNAME is untapped, players can't...  [0, 0, 0, 0, 0, 1]  \\\n",
       "1       Enchant creature\\nEnchanted creature gets -3/-0.  [0, 1, 0, 0, 0, 0]   \n",
       "2      Choose one —\\n• Return target permanent card f...  [0, 0, 0, 0, 1, 0]   \n",
       "3      Flying (This creature can't be blocked except ...  [0, 1, 0, 0, 0, 0]   \n",
       "4       tap: Target creature loses your choice of fly...  [0, 1, 0, 0, 0, 0]   \n",
       "...                                                  ...                 ...   \n",
       "24444  When CARDNAME enters the battlefield, you may ...  [0, 0, 0, 0, 1, 0]   \n",
       "24445                                                     [1, 0, 0, 0, 0, 0]   \n",
       "24446  Target creature you control gains indestructib...  [0, 0, 1, 0, 0, 0]   \n",
       "24447  Red instant and sorcery spells you control hav...  [1, 0, 0, 1, 0, 0]   \n",
       "24448                    All Sliver creatures get +1/+1.  [1, 0, 0, 0, 0, 0]   \n",
       "\n",
       "           color_identity  flavour_text                             type_line   \n",
       "0      [0, 0, 0, 0, 0, 1]           NaN                              Artifact  \\\n",
       "1      [0, 1, 0, 0, 0, 0]           NaN                    Enchantment — Aura   \n",
       "2      [0, 0, 0, 0, 1, 0]           NaN                               Sorcery   \n",
       "3      [0, 1, 0, 0, 0, 0]           NaN                       Creature — Bird   \n",
       "4      [0, 1, 0, 0, 0, 0]           NaN                     Creature — Sponge   \n",
       "...                   ...           ...                                   ...   \n",
       "24444  [0, 0, 0, 0, 1, 0]           NaN                     Creature — Insect   \n",
       "24445  [1, 0, 0, 0, 0, 0]           NaN                Creature — Elf Soldier   \n",
       "24446  [0, 0, 1, 0, 0, 0]           NaN                               Instant   \n",
       "24447  [1, 0, 0, 1, 0, 0]           NaN  Legendary Creature — Minotaur Cleric   \n",
       "24448  [1, 0, 0, 0, 0, 0]           NaN                     Creature — Sliver   \n",
       "\n",
       "      power toughness  set  \n",
       "0      None      None  7ed  \n",
       "1      None      None  m14  \n",
       "2      None      None  c19  \n",
       "3         1         2  9ed  \n",
       "4         1         1  ulg  \n",
       "...     ...       ...  ...  \n",
       "24444     4         5  hou  \n",
       "24445     1         2  s99  \n",
       "24446  None      None  hou  \n",
       "24447     4         6  2x2  \n",
       "24448     1         1  tsr  \n",
       "\n",
       "[24449 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = pd.read_json(\"data/cards.json\")\n",
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b068720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words\n",
    "\n",
    "def text_preprocess(input_text):\n",
    "    # remove all stop words\n",
    "    input_text = ' '.join([word for word in input_text.split() if word not in stopwords])\n",
    "\n",
    "    input_text = ''.join([char for char in input_text if char.isalnum() or char == '/' or char == ' '])\n",
    "\n",
    "    return input_text\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# input_text = type_line + rules_text (if not None) + power / toughness (if not None)\n",
    "for index, card in cards.iterrows():\n",
    "\n",
    "    input_text = card['type_line']\n",
    "    if card['rules_text'] is not None:\n",
    "        input_text += '\\n' + card['rules_text']\n",
    "    if card['power'] is not None:\n",
    "        input_text += '\\n' + card['power'] + '/' + card['toughness']\n",
    "\n",
    "    input_text = text_preprocess(input_text)\n",
    "    \n",
    "    X.append(input_text)\n",
    "    Y.append(card[\"color_identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5dddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5)\n",
    "\n",
    "nr_of_targets= 5\n",
    "\n",
    "# Remove colorless from array and convert from int to float32\n",
    "y_train = [np.asarray(y)[0:nr_of_targets].astype('float32').ravel() for y in y_train] \n",
    "y_test = [np.asarray(y)[0:nr_of_targets].astype('float32').ravel() for y in y_test]\n",
    "y_val = [np.asarray(y)[0:nr_of_targets].astype('float32').ravel() for y in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5efc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50\n",
    "\n",
    "# Testing Bert tokenizer on the dataset\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "inputs = tokenizer.batch_encode_plus(\n",
    "            x_train,\n",
    "            None,\n",
    "            max_length= maxlen,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False, \n",
    "            return_attention_mask= True,#diff normal/pad tokens\n",
    "            truncation= True,# Truncate data beyond max length\n",
    "            return_tensors = 'pt' # PyTorch Tensor format\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e63135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  140, 11811,  5332,  2896,  2087,  9240,   122,  2448, 24930,  1181,\n",
       "         1299,  1161,  2942,   124,   120,   123,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of tokens\n",
    "inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9013673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', '##rea', '##ture', 'El', '##f', 'Scout', '1', 'green', 'Ad', '##d', 'man', '##a', 'color', '3', '/', '2', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# Converting tokens back to text\n",
    "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2746316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the data into a Torch Dataset. This can be used for training in torch\n",
    "class CardDataset (Dataset):\n",
    "    def __init__(self, cards, colors, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cards = cards\n",
    "        self.labels = colors\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cards)\n",
    "    \n",
    "    def __getitem__(self, item_idx):\n",
    "        text = self.cards[item_idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length= self.max_len,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            return_attention_mask= True,\n",
    "            truncation=True,\n",
    "            return_tensors = 'pt'\n",
    "          )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "               \n",
    "        return {\n",
    "          'text': text,\n",
    "          'input_ids': input_ids ,\n",
    "          'attention_mask': attn_mask,\n",
    "          'labels':torch.tensor(self.labels[item_idx],dtype= torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a9aaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataset using training data\n",
    "train_dataset = CardDataset(\n",
    "  x_train, y_train,\n",
    "  tokenizer,\n",
    "  max_len=50\n",
    ")\n",
    "\n",
    "sample_item = train_dataset[0]\n",
    "sample_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9ca109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creature  Elf Scout 1 green Add mana color 3/2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f30fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_item[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4344d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training, validation and test datasets are warped into a lightning.pytorch.LightningDataModule\n",
    "class CardDataModule (pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self,x_train,y_train,x_val,y_val,x_test,y_test,tokenizer, batch_size=32,max_token_len=50):\n",
    "        super().__init__()\n",
    "        self.train_text = x_train\n",
    "        self.train_label = y_train\n",
    "        self.val_text = x_val\n",
    "        self.val_label = y_val\n",
    "        self.test_text = x_test\n",
    "        self.test_label = y_test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    # Setup the datasets used during training/testing\n",
    "    def setup(self, stage):\n",
    "        self.train_dataset = CardDataset(cards=self.train_text, colors=self.train_label, tokenizer=self.tokenizer,max_len= self.max_token_len)\n",
    "        self.val_dataset= CardDataset(cards=self.val_text, colors=self.val_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.test_dataset = CardDataset(cards=self.test_text, colors=self.test_label,tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "\n",
    "    # Create Torch DataLoaders for the 3 datasets \n",
    "    def train_dataloader(self):\n",
    "         return DataLoader(self.train_dataset,batch_size= self.batch_size, shuffle = True)\n",
    "    def val_dataloader(self):\n",
    "         return DataLoader (self.val_dataset,batch_size= self.batch_size)\n",
    "    def test_dataloader(self):\n",
    "         return DataLoader (self.test_dataset,batch_size= self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e937df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "N_EPOCHS = 4\n",
    "BATCH_SIZE = 12\n",
    "MAX_LEN = 50\n",
    "\n",
    "# Create the DataModule\n",
    "card_data_module = CardDataModule(x_train, y_train, x_val, y_val, x_test, y_test, tokenizer, BATCH_SIZE, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a00584b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lightning.pytorch.LightningModule is the model that will be trained\n",
    "# Includes the pretrained Bert module as well as an additional Linear layer for our classification\n",
    "class CardClassifier(pl.LightningModule):\n",
    "    # Set up the classifier        \n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased', return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.BCELoss()\n",
    "            \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        output = torch.sigmoid(output)    \n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "          optimizer,\n",
    "          num_warmup_steps=self.n_warmup_steps,\n",
    "          num_training_steps=self.n_training_steps\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "          optimizer=optimizer,\n",
    "          lr_scheduler=dict(\n",
    "            scheduler=scheduler,\n",
    "            interval='step'\n",
    "          )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8128b6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1303, 6516)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define number of training steps\n",
    "steps_per_epoch=len(x_train) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "\n",
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c86879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "307c949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = CardClassifier(\n",
    "  n_classes=nr_of_targets,\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b66dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to save the best model to checkpoints/best-checkpoint.ckpt\n",
    "# Checkpoint is overwritten if the val_loss of the new Epoch is better than the current best\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "  dirpath=\"checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c243375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Anaconda\\envs\\lightning\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "# lightning.pytorch.Trainer is a high-level abstraction that manages most of the training\n",
    "trainer = pl.Trainer(\n",
    "  callbacks=[checkpoint_callback],\n",
    "  max_epochs=N_EPOCHS,\n",
    "  enable_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "112d9d2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params\n",
      "-----------------------------------------\n",
      "0 | bert       | BertModel | 108 M \n",
      "1 | classifier | Linear    | 3.8 K \n",
      "2 | criterion  | BCELoss   | 0     \n",
      "-----------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.256   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\lightning\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Anaconda\\envs\\lightning\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52bd63539f044beb7804df908ab910f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1630: 'val_loss' reached 0.27665 (best 0.27665), saving model to 'C:\\\\Users\\\\Peter Helf\\\\Desktop\\\\IT-SEC\\\\Master\\\\AI\\\\semester 2\\\\NLP\\\\nlp-magic-color-identifier\\\\checkpoints\\\\best-checkpoint.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 3260: 'val_loss' reached 0.24652 (best 0.24652), saving model to 'C:\\\\Users\\\\Peter Helf\\\\Desktop\\\\IT-SEC\\\\Master\\\\AI\\\\semester 2\\\\NLP\\\\nlp-magic-color-identifier\\\\checkpoints\\\\best-checkpoint.ckpt' as top 1\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using the trainer\n",
    "# The warning that num_workers is set too low and might be a bottleneck is displayed\n",
    "# Changeing the value of num_workers does however lead to different errors\n",
    "# This seems to be a problem with jupyter notebook:\n",
    "# https://stackoverflow.com/questions/32489352/multiprocessing-program-has-attributeerror-in-anaconda-notebook\n",
    "trainer.fit(model, card_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26984033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display val_loss of final epoch\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4f5e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the final checkpoint from file\n",
    "trained_model = CardClassifier.load_from_checkpoint(\n",
    "  'checkpoints/best-checkpoint.ckpt',\n",
    "  n_classes=nr_of_targets\n",
    ")\n",
    "trained_model = trained_model.to(device)\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93206104",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "# Create predictions for our test data. This might take 1-2 minutes\n",
    "for i in range(len(x_test)):\n",
    "    encoding = tokenizer.encode_plus(\n",
    "      x_test[i],\n",
    "      add_special_tokens=True,\n",
    "      max_length=50,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    _, prediction = trained_model(encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device))\n",
    "    \n",
    "    predictions.append(prediction.flatten())\n",
    "    labels.append(torch.from_numpy(y_test[i]))\n",
    "    \n",
    "predictions = torch.stack(predictions).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d292e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "750a9cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9420, 0.1281, 0.2823, 0.0226, 0.1364],\n",
       "        [0.0051, 0.0369, 0.0119, 0.0105, 0.0054],\n",
       "        [0.0468, 0.0018, 0.0152, 0.8669, 0.0812],\n",
       "        ...,\n",
       "        [0.0107, 0.4624, 0.9094, 0.0765, 0.0080],\n",
       "        [0.0175, 0.0060, 0.1797, 0.9400, 0.0063],\n",
       "        [0.0059, 0.0049, 0.7363, 0.0204, 0.7023]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23a40484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.9442)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy, F1Score, AUROC\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = Accuracy(task='multilabel', num_labels=nr_of_targets, threshold=0.5)\n",
    "print(\"Accuracy: \", accuracy(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9536b9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           w       0.88      0.81      0.84       516\n",
      "           u       0.89      0.83      0.86       498\n",
      "           b       0.91      0.83      0.87       534\n",
      "           r       0.93      0.83      0.88       538\n",
      "           g       0.89      0.84      0.86       513\n",
      "\n",
      "   micro avg       0.90      0.83      0.86      2599\n",
      "   macro avg       0.90      0.83      0.86      2599\n",
      "weighted avg       0.90      0.83      0.86      2599\n",
      " samples avg       0.78      0.76      0.76      2599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "LABELS = [\"w\", \"u\", \"b\", \"r\", \"g\"]\n",
    "\n",
    "y_pred = predictions.numpy()\n",
    "y_true = labels.numpy()\n",
    "\n",
    "upper, lower = 1, 0\n",
    "\n",
    "y_pred = np.where(y_pred > 0.5, upper, lower)\n",
    "\n",
    "print(classification_report(\n",
    "  y_true, \n",
    "  y_pred, \n",
    "  target_names=LABELS, \n",
    "  zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11507677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1870   59]\n",
      "  [  96  420]]\n",
      "\n",
      " [[1898   49]\n",
      "  [  83  415]]\n",
      "\n",
      " [[1869   42]\n",
      "  [  92  442]]\n",
      "\n",
      " [[1875   32]\n",
      "  [  93  445]]\n",
      "\n",
      " [[1880   52]\n",
      "  [  84  429]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "confusion_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01b946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card text:  Instant You exile red card hand pay spells mana cost CARDNAME deals 4 damage divided choose number target creatures\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '0.000', '0.000', '1.000', '0.000']\n",
      "Predicted colors: ['0.015', '0.014', '0.014', '0.988', '0.016']\n",
      "\n",
      "Card text:  Creature  Human Warrior 3/1\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['1.000', '0.000', '0.000', '0.000', '0.000']\n",
      "Predicted colors: ['0.071', '0.004', '0.207', '0.428', '0.110']\n",
      "\n",
      "Card text:  Sorcery Destroy target creature You gain life equal toughness You search library and/or graveyard card named Vraska Regal Gorgon reveal it hand If search library way shuffle\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '0.000', '1.000', '0.000', '1.000']\n",
      "Predicted colors: ['0.098', '0.012', '0.936', '0.016', '0.119']\n",
      "\n",
      "Card text:  Sorcery Return target permanent card mana value 3 graveyard battlefield If spell cast graveyard copy spell choose new target copy Flashback 4 white You cast card graveyard flashback cost Then exile it\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['1.000', '0.000', '0.000', '0.000', '0.000']\n",
      "Predicted colors: ['0.992', '0.033', '0.041', '0.012', '0.035']\n",
      "\n",
      "Card text:  Artifact Creature  Golem 1 Sacrifice CARDNAME Add red green white 3/3\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['1.000', '0.000', '0.000', '1.000', '1.000']\n",
      "Predicted colors: ['0.986', '0.084', '0.120', '0.978', '0.948']\n",
      "\n",
      "Card text:  Artifact As CARDNAME enters battlefield choose creature type Creatures control chosen type 1/1 Whenever cast creature spell chosen type draw card\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '0.000', '0.000', '0.000', '0.000']\n",
      "Predicted colors: ['0.024', '0.027', '0.008', '0.004', '0.014']\n",
      "\n",
      "Card text:  Enchantment  Aura Enchant creature Enchanted creature gets 2/2 haste\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '0.000', '0.000', '1.000', '0.000']\n",
      "Predicted colors: ['0.009', '0.005', '0.030', '0.975', '0.057']\n",
      "\n",
      "Card text:  Instant Destroy artifacts enchantments For permanent destroyed way controller creates 3/3 green Centaur creature token\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '0.000', '0.000', '0.000', '1.000']\n",
      "Predicted colors: ['0.223', '0.006', '0.004', '0.011', '0.928']\n",
      "\n",
      "Card text:  Legendary Creature  Human Rogue Whenever creature control dies investigate Create Clue token Its artifact  2 Sacrifice artifact Draw card Whenever sacrifice token surveil 1 Look card library You card graveyard 4/4\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '1.000', '1.000', '0.000', '0.000']\n",
      "Predicted colors: ['0.159', '0.809', '0.817', '0.038', '0.222']\n",
      "\n",
      "Card text:  Artifact 2 tap Put charge counter CARDNAME tap Remove number charge counters CARDNAME Add blue add additional blue charge counter removed way\n",
      "Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\n",
      "Actual colors:    ['0.000', '1.000', '0.000', '0.000', '0.000']\n",
      "Predicted colors: ['0.009', '0.926', '0.014', '0.012', '0.009']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some prediction samples\n",
    "import random\n",
    "\n",
    "for i in random.sample(range(len(x_test)), 10):\n",
    "    test_text = x_test[i]\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(\n",
    "      test_text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=50,\n",
    "      return_token_type_ids=False,\n",
    "      padding=\"max_length\",\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    _, test_prediction = trained_model(encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device))\n",
    "    test_prediction = test_prediction.cpu().flatten().numpy()\n",
    "    \n",
    "    \n",
    "    formatted_y_test = [\"%.3f\"%item for item in y_test[i]]\n",
    "    formatted_prediction = [\"%.3f\"%item for item in test_prediction]\n",
    "    \n",
    "    print(\"Card text: \", test_text)\n",
    "    print(\"Colors:           [   w   ,    u   ,    b   ,    r   ,    g   ]\")\n",
    "    print(\"Actual colors:   \", formatted_y_test)\n",
    "    print(\"Predicted colors:\", formatted_prediction)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d488fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
